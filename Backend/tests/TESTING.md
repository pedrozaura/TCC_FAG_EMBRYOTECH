# ğŸ§ª Guia de Testes - Embryotech

Este documento descreve a estrutura de testes e como executÃ¡-los no projeto Embryotech.

## ğŸ“‹ Ãndice

- [Estrutura de Testes](#estrutura-de-testes)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Executando Testes](#executando-testes)
- [Tipos de Testes](#tipos-de-testes)
- [Cobertura de CÃ³digo](#cobertura-de-cÃ³digo)
- [Boas PrÃ¡ticas](#boas-prÃ¡ticas)

## ğŸ—ï¸ Estrutura de Testes

```
tests/
â”œâ”€â”€ conftest.py                 # Fixtures e configuraÃ§Ãµes compartilhadas
â”œâ”€â”€ test_models.py             # Testes dos modelos (User, Parametro, Leitura, Log)
â”œâ”€â”€ test_auth.py               # Testes de autenticaÃ§Ã£o e autorizaÃ§Ã£o
â”œâ”€â”€ test_parametros_api.py     # Testes da API de parÃ¢metros
â”œâ”€â”€ test_leituras_api.py       # Testes da API de leituras
â””â”€â”€ test_logging.py            # Testes do sistema de logging
```

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Instalar DependÃªncias de Teste

```bash
pip install -r requirements-test.txt
```

### 2. Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` para testes (ou use `.env.test`):

```bash
# Banco de dados de teste (SQLite em memÃ³ria ou PostgreSQL separado)
DB_USER=testuser
DB_PASSWORD=testpass
DB_HOST=localhost
DB_PORT=5432
DB_NAME=embryotech_test

# Chaves secretas (apenas para testes)
SECRET_KEY=test-secret-key
JWT_SECRET_KEY=test-jwt-secret
```

## ğŸš€ Executando Testes

### Executar Todos os Testes

```bash
# Linux/Mac
chmod +x run_tests.sh
./run_tests.sh

# Ou diretamente com pytest
pytest tests/ -v
```

### Executar Testes EspecÃ­ficos

```bash
# Usar script helper
chmod +x run_specific_tests.sh

# Testes de modelos
./run_specific_tests.sh models

# Testes de autenticaÃ§Ã£o
./run_specific_tests.sh auth

# Testes de API
./run_specific_tests.sh api

# Testes de logging
./run_specific_tests.sh logging

# Testes de parÃ¢metros
./run_specific_tests.sh parametros

# Testes de leituras
./run_specific_tests.sh leituras

# Apenas testes rÃ¡pidos
./run_specific_tests.sh fast

# Re-executar testes que falharam
./run_specific_tests.sh failed
```

### Executar Teste Individual

```bash
# Executar um arquivo especÃ­fico
pytest tests/test_models.py -v

# Executar uma classe especÃ­fica
pytest tests/test_models.py::TestUserModel -v

# Executar um teste especÃ­fico
pytest tests/test_models.py::TestUserModel::test_criar_usuario -v
```

## ğŸ“Š Tipos de Testes

### 1. Testes UnitÃ¡rios de Modelos (`test_models.py`)

Testam os modelos de dados isoladamente:

- âœ… CriaÃ§Ã£o de usuÃ¡rios
- âœ… Hash e verificaÃ§Ã£o de senhas
- âœ… GeraÃ§Ã£o e verificaÃ§Ã£o de tokens JWT
- âœ… Modelos de ParÃ¢metro, Leitura e Log
- âœ… MÃ©todos to_dict() e relacionamentos

**Executar:**
```bash
pytest tests/test_models.py -v
```

### 2. Testes de AutenticaÃ§Ã£o (`test_auth.py`)

Testam registro, login e autorizaÃ§Ã£o:

- âœ… Registro de novos usuÃ¡rios
- âœ… Login com credenciais vÃ¡lidas/invÃ¡lidas
- âœ… ValidaÃ§Ã£o de tokens JWT
- âœ… Controle de acesso (admin vs usuÃ¡rio comum)
- âœ… ExpiraÃ§Ã£o de tokens

**Executar:**
```bash
pytest tests/test_auth.py -v
```

### 3. Testes de API de ParÃ¢metros (`test_parametros_api.py`)

Testam endpoints de gerenciamento de parÃ¢metros:

- âœ… CRUD de parÃ¢metros (apenas admin)
- âœ… Listagem de empresas e lotes
- âœ… Busca e filtros
- âœ… ValidaÃ§Ã£o de dados
- âœ… Controle de permissÃµes

**Executar:**
```bash
pytest tests/test_parametros_api.py -v
```

### 4. Testes de API de Leituras (`test_leituras_api.py`)

Testam endpoints de leituras de dados:

- âœ… CRUD de leituras
- âœ… ValidaÃ§Ã£o de campos (umidade, temperatura, pressÃ£o)
- âœ… Formatos de data
- âœ… Testes de integraÃ§Ã£o (criar, atualizar, deletar)

**Executar:**
```bash
pytest tests/test_leituras_api.py -v
```

### 5. Testes de Logging (`test_logging.py`)

Testam o sistema de auditoria:

- âœ… Registro automÃ¡tico de logs
- âœ… Logs de login/logout
- âœ… Logs de alteraÃ§Ãµes em parÃ¢metros
- âœ… Logs de operaÃ§Ãµes CRUD
- âœ… API de consulta de logs (admin)
- âœ… Filtros e buscas

**Executar:**
```bash
pytest tests/test_logging.py -v
```

## ğŸ“ˆ Cobertura de CÃ³digo

### Gerar RelatÃ³rio de Cobertura

```bash
# Executar testes com cobertura
pytest tests/ --cov=. --cov-report=html --cov-report=term

# Abrir relatÃ³rio HTML
# Linux
xdg-open htmlcov/index.html

# Mac
open htmlcov/index.html

# Windows
start htmlcov/index.html
```

### Verificar Cobertura MÃ­nima

```bash
# Falhar se cobertura for menor que 80%
pytest tests/ --cov=. --cov-fail-under=80
```

## ğŸ¯ Fixtures DisponÃ­veis

As fixtures estÃ£o definidas em `tests/conftest.py`:

| Fixture | DescriÃ§Ã£o |
|---------|-----------|
| `app` | AplicaÃ§Ã£o Flask configurada para testes |
| `client` | Cliente HTTP para fazer requisiÃ§Ãµes |
| `db_session` | SessÃ£o de banco limpa para cada teste |
| `usuario_comum` | UsuÃ¡rio nÃ£o-admin para testes |
| `usuario_admin` | UsuÃ¡rio administrador para testes |
| `token_usuario_comum` | Token JWT de usuÃ¡rio comum |
| `token_usuario_admin` | Token JWT de administrador |
| `auth_headers_comum` | Headers com autenticaÃ§Ã£o de usuÃ¡rio comum |
| `auth_headers_admin` | Headers com autenticaÃ§Ã£o de admin |
| `parametro_exemplo` | ParÃ¢metro de exemplo no banco |
| `leitura_exemplo` | Leitura de exemplo no banco |
| `multiplos_parametros` | VÃ¡rios parÃ¢metros para testes de listagem |
| `multiplas_leituras` | VÃ¡rias leituras para testes de filtro |

## âœ… Boas PrÃ¡ticas

### 1. Nomenclatura de Testes

```python
# âœ… BOM - Descritivo e claro
def test_criar_usuario_com_email_duplicado_retorna_erro():
    pass

# âŒ RUIM - Vago
def test_user():
    pass
```

### 2. OrganizaÃ§Ã£o por Classes

```python
class TestUserModel:
    """Testes relacionados ao modelo User"""
    
    def test_criar_usuario(self):
        pass
    
    def test_verificar_senha(self):
        pass
```

### 3. Usar Fixtures

```python
# âœ… BOM - Usar fixtures
def test_criar_parametro(client, auth_headers_admin):
    response = client.post('/api/parametros', headers=auth_headers_admin)
    assert response.status_code == 201

# âŒ RUIM - Criar tudo manualmente
def test_criar_parametro():
    app = create_app()
    user = create_user()
    token = generate_token(user)
    # ...muito cÃ³digo repetitivo
```

### 4. Testes Independentes

```python
# âœ… BOM - Cada teste Ã© independente
def test_criar_usuario(db_session):
    user = User(username='test')
    db_session.add(user)
    db_session.commit()
    assert user.id is not None

# âŒ RUIM - Depende de outros testes
def test_atualizar_usuario():
    # Assume que usuÃ¡rio foi criado em outro teste
    user = User.query.first()
    user.email = 'new@email.com'
```

### 5. Assertions Claras

```python
# âœ… BOM - Mensagens de erro claras
assert response.status_code == 200, f"Esperado 200, recebido {response.status_code}"
assert user.is_admin is True, "UsuÃ¡rio deveria ser admin"

# âŒ RUIM - Sem contexto
assert response.status_code == 200
assert user.is_admin
```

## ğŸ› Debugging de Testes

### Ver Output Completo

```bash
pytest tests/test_models.py -v -s
```

### Parar no Primeiro Erro

```bash
pytest tests/ -x
```

### Modo Debug com PDB

```bash
pytest tests/test_models.py --pdb
```

### Ver Testes mais Lentos

```bash
pytest tests/ --durations=10
```

## ğŸ“ Checklist de Testes

Antes de fazer commit, verifique:

- [ ] Todos os testes passam
- [ ] Cobertura de cÃ³digo >= 80%
- [ ] Novos features tÃªm testes
- [ ] Testes sÃ£o independentes
- [ ] NÃ£o hÃ¡ prints ou debugs esquecidos
- [ ] Nomes de testes sÃ£o descritivos

## ğŸ”„ IntegraÃ§Ã£o ContÃ­nua (CI/CD)

### GitHub Actions (exemplo)

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: |
          pip install -r requirements-test.txt
      - name: Run tests
        run: |
          pytest tests/ --cov=. --cov-report=xml
      - name: Upload coverage
        uses: codecov/codecov-action@v2
```

## ğŸ“ Suporte

Se encontrar problemas com os testes:

1. Verifique se todas as dependÃªncias estÃ£o instaladas
2. Confirme que o banco de dados de teste estÃ¡ configurado
3. Revise os logs de erro detalhados
4. Entre em contato com a equipe de desenvolvimento

---

**Desenvolvido por Outside Agrotech** ğŸŒ±
